import streamlit as st
import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

#mettre le cache 

os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

st.title("âš½ GenAI Predictions ")
st.write(
    " **Welcome in your match predictions app !**"
)

@st.cache_resource
def get_model():
    return ChatGoogleGenerativeAI(model="gemini-2.0-flash")

model = get_model()

prompt_template = ChatPromptTemplate.from_messages(
    [
        ("system", "do not answer the query but output the  teams from the query like 'Barcelona, Real Madrid' "),
        ("user", "{input}")
    ]
)

user_input = st.text_input("What do you want me to predict ? 0_0 ")

# @st.cache_data
# def generate_response(user_input):
#     #st.session_state['count'] += 1
#     prompt = prompt_template.invoke({"input": user_input})
#     response = model.invoke(prompt)
#     query_result = response.content
#     teams = query_result.split(",") if "," in query_result else [query_result]
#     query_result1, query_result2 = teams[0], teams[1]


#     return response.content, query_result1, query_result2

# if user_input:
#     st.write(generate_response(user_input))



def extraire_equipes(user_input):
  """
  Extrait les noms de deux Ã©quipes Ã  partir de la requÃªte d'un utilisateur
  en utilisant un modÃ¨le de langage.
  Args:
      user_input (str): La requÃªte de l'utilisateur concernant le rÃ©sultat d'un match.
      model: L'objet du modÃ¨le de langage Ã  utiliser pour l'infÃ©rence.
  Returns:
      tuple: Un tuple contenant les noms des deux Ã©quipes
             (query_result1, query_result2).
             Si une seule Ã©quipe est trouvÃ©e, le deuxiÃ¨me Ã©lÃ©ment sera None.
  """
  # CrÃ©ation du template de prompt pour le modÃ¨le de langage.
  prompt_template = ChatPromptTemplate.from_messages(
      [
          ("system", "Ne rÃ©ponds pas Ã  la question, mais extrais les Ã©quipes de la requÃªte comme 'Barcelona, Real Madrid' "),
          ("user", "{input}") # La requÃªte de l'utilisateur sera insÃ©rÃ©e ici.
      ]
  )

  # Appel du modÃ¨le de langage avec le prompt et la requÃªte de l'utilisateur.
  response = model.invoke(prompt_template.invoke({"input": user_input}))
  query_result = response.content # Extraction du contenu de la rÃ©ponse.

  # SÃ©paration des noms d'Ã©quipes en utilisant la virgule comme dÃ©limiteur.
  teams = query_result.split(",") if "," in query_result else [query_result]

  # Attribution des noms d'Ã©quipes aux variables query_result1 et query_result2.
  # Si une seule Ã©quipe est trouvÃ©e, query_result2 sera None.
  query_result1 = teams[0].strip() if teams else None  # Suppression des espaces inutiles.
  query_result2 = teams[1].strip() if len(teams) > 1 else None  # Suppression des espaces inutiles.

  return query_result1, query_result2 # Retourne les noms des Ã©quipes.

st.write(extraire_equipes(user_input))




def get_team_data(team_name, api_key="081a622178msh47c970908ee3fe1p175ee7jsndc3e70382bf5"):
    """
    RÃ©cupÃ¨re les informations dÃ©taillÃ©es d'une Ã©quipe sportive via SportAPI7.

    Args:
        team_name (str): Nom de l'Ã©quipe.
        api_key (str, optional): Votre clÃ© API SportAPI7.
                                  Par dÃ©faut : "a77e4d69aemshd774591d8fbc877p15616cjsn65f81709282b".

    Returns:
        dict: Dictionnaire contenant les donnÃ©es de l'Ã©quipe si trouvÃ©e,
              sinon un dictionnaire vide.
    """
    url = f"https://sportapi7.p.rapidapi.com/api/v1/search/teams/{team_name}/more"

    headers = {
        "x-rapidapi-key": api_key,
        "x-rapidapi-host": "sportapi7.p.rapidapi.com"
    }

    response = requests.get(url, headers=headers)
    data = response.json()

    team_data = {}
    if "teams" in data and isinstance(data["teams"], list) and len(data["teams"]) > 0:
        team_data = data["teams"][0]

    return team_data


# query_result = response.content

# # Je stocke les valeurs des deux Ã©quipes pour une utilisation future

# teams = query_result.split(",") if "," in query_result else [query_result]

# # Stocker dans des variables distinctes
# query_result1, query_result2 = teams[0], teams[1]



#####

# prompt = st.text_input("Enter your prompt:")

# @st.cache_data
# def generate_response(prompt):
#     return "Hello, " + prompt

# if prompt:
#     st.write(generate_response(prompt))


# prompt = st.chat_input("Say something")
# if prompt : 
#     st.write(f"User has sent the following prompt: {prompt}")


# #st.chat_message


# import numpy as np
# message = st.chat_message("assistant")
# message.write("Hello human")
# message.bar_chart(np.random.randn(30, 3))



# import streamlit as st
# import os 

# os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

# from langchain_google_genai import ChatGoogleGenerativeAI

# model = ChatGoogleGenerativeAI(model="gemini-2.0-flash")


# from langchain_core.prompts import ChatPromptTemplate

# prompt = st.text_input("What match do you want our AI to predict ex : 'manchester city vs real madrid '", key="match")


# prompt_template = ChatPromptTemplate.from_messages(
#     [
#         ("system", "do not answer the query but output the  teams from the query like 'Barcelona, Real Madrid' "),
#         ("user", "{prompt}")
#     ]
# )

# # user_input = 'What is the result between liverpool  and barcelona  '  # @param {type: "string"}



# response = model.invoke(prompt_template.invoke({"input": prompt}))

# query_result = response.content

# st.session_state.match

# # # Je stocke les valeurs des deux Ã©quipes pour une utilisation future

# # teams = query_result.split(",") if "," in query_result else [query_result]

# # # Stocker dans des variables distinctes
# # query_result1, query_result2 = teams[0], teams[1]

# # print(query_result1)
# # print(query_result2)




# # import streamlit as st
# # import pandas as pd

# # st.write("Hello, what would you like our AI to predict ? ")

# # df = pd.DataFrame({
# #     'first column': [1, 2, 3, 4],
# #     'second column': [10, 20, 30, 40]
# # })

# # option = st.selectbox(
# #     "Which number do you like best?",
# #     df['first column']
# # )

# # if option > 2:
# #     st.write("The option selected is above 2")

# # else :
# #     st.write("The option selected is below or equal to 2")



# # x = st.slider('x')  # ðŸ‘ˆ this is a widget
# # st.write(x, 'squared is', x * x)


# # prompt = st.text_input("What match do you want our AI to predict ex : 'manchester city vs real madrid '", key="match")

# # # You can access the value at any point with:
# # st.session_state.match

# # @st.cache_data
# # def generate_response(prompt):
# #     return "This is a response to your prompt: " + prompt
